{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Туториал по использованию предобученной модели RuBERT в задаче классификации твитов по тональности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb # pytorch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем 5000 позитивных и негативных твитов\n",
    "\n",
    "df_tweets = pd.read_csv('corpus.csv')\n",
    "df_tweets = df_tweets.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>channel</th>\n",
       "      <th>views_count_2</th>\n",
       "      <th>popularity</th>\n",
       "      <th>url</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2738</td>\n",
       "      <td>https telegra ph file fac41ad20abc38747e8a8 jp...</td>\n",
       "      <td>551</td>\n",
       "      <td>datarootlabs</td>\n",
       "      <td>3600</td>\n",
       "      <td>1.241379</td>\n",
       "      <td>https://t.me/datarootlabs/551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2241</td>\n",
       "      <td>анализ выживаемости survival analysis класс ст...</td>\n",
       "      <td>421</td>\n",
       "      <td>datalytx</td>\n",
       "      <td>2300</td>\n",
       "      <td>1.352941</td>\n",
       "      <td>https://t.me/datalytx/421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           1          2738   \n",
       "1           3          2241   \n",
       "\n",
       "                                                text   id       channel  \\\n",
       "0  https telegra ph file fac41ad20abc38747e8a8 jp...  551  datarootlabs   \n",
       "1  анализ выживаемости survival analysis класс ст...  421      datalytx   \n",
       "\n",
       "   views_count_2  popularity                            url  target  \n",
       "0           3600    1.241379  https://t.me/datarootlabs/551       1  \n",
       "1           2300    1.352941      https://t.me/datalytx/421       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8012, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# создаем токенайзер для модели BERT, для его инициализации достаточно указать словарь, на котором обучалась предобученная модель\n",
    "# BERT использует собственную токенизацию, никакой предобработки \n",
    "\n",
    "tokenizer = ppb.BertTokenizer(vocab_file='vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# токенизируем текст каждого твита, для BERT не требуется никакая дополнительная предобработка, лемматизация и прочее\n",
    "\n",
    "tokenized = df_tweets['text'].astype(str).str[:512].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       https telegra ph file fac41ad20abc38747e8a8 jp...\n",
       "1       анализ выживаемости survival analysis класс ст...\n",
       "2       одной из первых моих задач тут было внести нов...\n",
       "3       яндекс вчера выпустил тепловую карту цен на не...\n",
       "4       примерно так мы представляем себе студентов на...\n",
       "                              ...                        \n",
       "8007    15 часов видео про ml https www r bloggers com...\n",
       "8008    i have presented quantitative analysis of text...\n",
       "8009    https telegra ph file f8822e71b343d996bb29b pn...\n",
       "8010    о важности подбора правильной визуализации htt...\n",
       "8011    я думаю все из вас знают shopify конструктор д...\n",
       "Name: text, Length: 8012, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['text'].astype(str).str[:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https telegra ph file fac41ad20abc38747e8a8 jpg openai musenet для генерации музыки musenet нейронная сеть которая генерирует музыку из первых 5 нот для этого она использует множество различных инструментов и стилей послушать на soundcloud https soundcloud com openai audio статья https openai com blog musenet\n",
      "[101, 74034, 65041, 14751, 233, 23050, 96878, 49404, 36756, 2190, 2748, 3599, 237, 14962, 12551, 151, 241, 153, 233, 153, 45141, 14599, 12054, 82948, 12573, 271, 949, 58628, 13772, 82948, 12573, 271, 15175, 1997, 960, 10349, 1901, 72764, 11559, 883, 2980, 146, 29734, 949, 1250, 1151, 13604, 6979, 9666, 23971, 322, 5291, 323, 17635, 801, 19814, 88256, 74034, 19814, 88256, 6502, 14599, 12054, 77325, 7467, 7413, 74034, 14599, 12054, 6502, 98988, 82948, 12573, 271, 102]\n",
      "['https', 'tele', '##gr', '##a', 'ph', 'file', 'fac', '##41', '##ad', '##20', '##ab', '##c', '##38', '##74', '##7', '##e', '##8', '##a', '##8', 'jpg', 'open', '##ai', 'mus', '##ene', '##t', 'для', 'генерации', 'музыки', 'mus', '##ene', '##t', 'неи', '##рон', '##ная', 'сеть', 'которая', 'генерирует', 'музыку', 'из', 'первых', '5', 'нот', 'для', 'этого', 'она', 'использует', 'множество', 'различных', 'инструментов', 'и', 'стиле', '##и', 'послушать', 'на', 'sound', '##cloud', 'https', 'sound', '##cloud', 'com', 'open', '##ai', 'aud', '##io', 'статья', 'https', 'open', '##ai', 'com', 'blog', 'mus', '##ene', '##t']\n"
     ]
    }
   ],
   "source": [
    "# Пример токенизации текста: на входе - текст, а на выходе имеем массив с номерами токенов из словаря модели BERT\n",
    "\n",
    "print(df_tweets['text'][0])\n",
    "print(tokenized[0])\n",
    "print(tokenizer.tokenize(df_tweets['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем предобученную модель RuBERT из файла, \n",
    "# в json-файле конфигурации описаны параметры модели\n",
    "\n",
    "config = ppb.BertConfig.from_json_file('bert_config.json')\n",
    "model = ppb.BertModel.from_pretrained('pytorch_model.bin', config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# из-за того, что каждый твит в датасете имеет разную длину (количество токенов)\n",
    "# мы делаем паддинг - заполнение нулями каждого массива токенов до длины максимального массива\n",
    "# чтобы на выходе получить матрицу из токенизированных текстов одной длины\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8012, 310)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на размерность матрицы токенизированных твитов после паддинга\n",
    "\n",
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8012, 310)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Накладываем маску на значимые токены\n",
    "# В данном случае нам важны все слова кроме нулевых токенов, появившихся на предыдущем шаге паддинга\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:54<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# а теперь сформируем вектора текстов с помощью модели RuBERT\n",
    "\n",
    "# это не быстрый процесс, импортируем инструмент для визуализации времени обработки в цикле\n",
    "from tqdm import tqdm\n",
    "\n",
    "# для того, чтобы модель отработала в условиях ограниченных ресурсов - оперативной памяти, мы разделяем входной датасет на батчи.\n",
    "# при батче в 100 твитов потребление оперативной памяти укладывается в 1Гб\n",
    "batch_size = 100\n",
    "\n",
    "# Делаем пустой список для хранения эмбеддингов (векторов) твитов\n",
    "embeddings = []\n",
    "\n",
    "for i in tqdm(range(padded.shape[0] // batch_size)):\n",
    "        # преобразуем батч с токенизированными твитами в тензор \n",
    "        # по сути тензор - это многомерный массив, который может быть обработан нейронной сетью\n",
    "        input_ids = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]).to('cuda') \n",
    "        \n",
    "        # создаем тензор и для подготовленной маски\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).to('cuda')\n",
    "        \n",
    "        # передаем в модель BERT тензор из твитов и маску - на выходе получаем эмбеддинги - вектор текста твита\n",
    "        # torch.no_grad() - для ускорения инференса модели отключим рассчет градиентов\n",
    "        with torch.no_grad():\n",
    "               last_hidden_states = model(input_ids, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        # в итоге собираем все эмбеддинги твитов в features\n",
    "        embeddings.append(last_hidden_states[0][:,0,:].cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем список батчей эмбеддингов в numpy-матрицу \n",
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выводим размерность полученной матрицы эмбеддингов\n",
    "# данная модель BERT формирует вектора текстов в 768-мерном пространстве признаков\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Выводим пример эмбеддинга для твита - осторожно много цифр!\n",
    "\n",
    "print(df_tweets['text'][1])\n",
    "print(features[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки для обучения классификатора на logreg и оценки качества\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраним целевую переменную: метку тональности позитив/негатив\n",
    "\n",
    "labels = df_tweets['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "8007    1\n",
       "8008    0\n",
       "8009    0\n",
       "8010    1\n",
       "8011    1\n",
       "Name: target, Length: 8012, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 768)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8012,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Разделяем матрицу признаков и целевую переменную на обучающий и тестовый набор\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels[:8000], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'iterations': 10000,\n",
    "    'learning_rate': 0.001,\n",
    "    'eval_metric': 'AUC',\n",
    "    #'eval_metric': 'Accuracy',\n",
    "    'loss_function': 'MultiClass',\n",
    "    'task_type': 'GPU',\n",
    "    'early_stopping_rounds': 1000,\n",
    "    'use_best_model': True,\n",
    "    'objective':\"MultiClass\",\n",
    "    'verbose': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = pd.DataFrame(train_features) #X_train\n",
    "X_val =  pd.DataFrame(test_features)\n",
    "y_tr = train_labels\n",
    "y_val = test_labels\n",
    "\n",
    "train_pool = Pool(\n",
    "    X_tr, \n",
    "    y_tr\n",
    ")\n",
    "valid_pool = Pool(\n",
    "    X_val, \n",
    "    y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 7279.5 Total: 11019.4375\n",
      "AUC is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.5825471\tbest: 0.5825471 (0)\ttotal: 11.1ms\tremaining: 1m 50s\n",
      "100:\ttest: 0.6461223\tbest: 0.6477594 (94)\ttotal: 996ms\tremaining: 1m 37s\n",
      "200:\ttest: 0.6538916\tbest: 0.6541755 (199)\ttotal: 1.95s\tremaining: 1m 35s\n",
      "300:\ttest: 0.6584509\tbest: 0.6586210 (287)\ttotal: 2.88s\tremaining: 1m 32s\n",
      "400:\ttest: 0.6600336\tbest: 0.6608843 (368)\ttotal: 3.76s\tremaining: 1m 30s\n",
      "500:\ttest: 0.6631843\tbest: 0.6634453 (494)\ttotal: 4.63s\tremaining: 1m 27s\n",
      "600:\ttest: 0.6659155\tbest: 0.6659155 (600)\ttotal: 5.5s\tremaining: 1m 26s\n",
      "700:\ttest: 0.6673158\tbest: 0.6674136 (699)\ttotal: 6.46s\tremaining: 1m 25s\n",
      "800:\ttest: 0.6672783\tbest: 0.6674808 (764)\ttotal: 7.38s\tremaining: 1m 24s\n",
      "900:\ttest: 0.6688452\tbest: 0.6694066 (893)\ttotal: 8.28s\tremaining: 1m 23s\n",
      "1000:\ttest: 0.6716665\tbest: 0.6719069 (997)\ttotal: 9.18s\tremaining: 1m 22s\n",
      "1100:\ttest: 0.6738043\tbest: 0.6738043 (1100)\ttotal: 10.1s\tremaining: 1m 21s\n",
      "1200:\ttest: 0.6745752\tbest: 0.6747139 (1154)\ttotal: 11s\tremaining: 1m 20s\n",
      "1300:\ttest: 0.6754889\tbest: 0.6754889 (1300)\ttotal: 11.9s\tremaining: 1m 19s\n",
      "1400:\ttest: 0.6769526\tbest: 0.6771433 (1390)\ttotal: 12.8s\tremaining: 1m 18s\n",
      "1500:\ttest: 0.6783437\tbest: 0.6783437 (1500)\ttotal: 13.7s\tremaining: 1m 17s\n",
      "1600:\ttest: 0.6796626\tbest: 0.6796753 (1594)\ttotal: 14.7s\tremaining: 1m 16s\n",
      "1700:\ttest: 0.6807635\tbest: 0.6808625 (1696)\ttotal: 15.6s\tremaining: 1m 16s\n",
      "1800:\ttest: 0.6814211\tbest: 0.6815865 (1794)\ttotal: 16.5s\tremaining: 1m 15s\n",
      "1900:\ttest: 0.6825595\tbest: 0.6828594 (1896)\ttotal: 17.3s\tremaining: 1m 13s\n",
      "2000:\ttest: 0.6835845\tbest: 0.6836768 (1989)\ttotal: 18.2s\tremaining: 1m 12s\n",
      "2100:\ttest: 0.6845449\tbest: 0.6845449 (2100)\ttotal: 19.1s\tremaining: 1m 11s\n",
      "2200:\ttest: 0.6860403\tbest: 0.6860403 (2200)\ttotal: 20.1s\tremaining: 1m 11s\n",
      "2300:\ttest: 0.6863962\tbest: 0.6869209 (2240)\ttotal: 21s\tremaining: 1m 10s\n",
      "2400:\ttest: 0.6875427\tbest: 0.6875486 (2399)\ttotal: 21.9s\tremaining: 1m 9s\n",
      "2500:\ttest: 0.6882351\tbest: 0.6882351 (2500)\ttotal: 22.9s\tremaining: 1m 8s\n",
      "2600:\ttest: 0.6883202\tbest: 0.6886488 (2546)\ttotal: 23.9s\tremaining: 1m 7s\n",
      "2700:\ttest: 0.6891864\tbest: 0.6893411 (2698)\ttotal: 24.8s\tremaining: 1m 7s\n",
      "2800:\ttest: 0.6901687\tbest: 0.6902253 (2799)\ttotal: 25.7s\tremaining: 1m 6s\n",
      "2900:\ttest: 0.6910776\tbest: 0.6911831 (2897)\ttotal: 26.6s\tremaining: 1m 5s\n",
      "3000:\ttest: 0.6912465\tbest: 0.6914895 (2917)\ttotal: 27.5s\tremaining: 1m 4s\n",
      "3100:\ttest: 0.6924162\tbest: 0.6926720 (3080)\ttotal: 28.4s\tremaining: 1m 3s\n",
      "3200:\ttest: 0.6932741\tbest: 0.6932838 (3199)\ttotal: 29.3s\tremaining: 1m 2s\n",
      "3300:\ttest: 0.6936718\tbest: 0.6938640 (3249)\ttotal: 30.2s\tremaining: 1m 1s\n",
      "3400:\ttest: 0.6943091\tbest: 0.6944214 (3384)\ttotal: 31.1s\tremaining: 1m\n",
      "3500:\ttest: 0.6949566\tbest: 0.6949566 (3500)\ttotal: 32.1s\tremaining: 59.6s\n",
      "3600:\ttest: 0.6952979\tbest: 0.6954587 (3595)\ttotal: 33s\tremaining: 58.7s\n",
      "3700:\ttest: 0.6955983\tbest: 0.6958575 (3625)\ttotal: 33.9s\tremaining: 57.7s\n",
      "3800:\ttest: 0.6961574\tbest: 0.6961834 (3791)\ttotal: 34.8s\tremaining: 56.7s\n",
      "3900:\ttest: 0.6965474\tbest: 0.6965956 (3885)\ttotal: 35.6s\tremaining: 55.7s\n",
      "4000:\ttest: 0.6975059\tbest: 0.6975920 (3994)\ttotal: 36.5s\tremaining: 54.7s\n",
      "4100:\ttest: 0.6979307\tbest: 0.6980522 (4098)\ttotal: 37.4s\tremaining: 53.8s\n",
      "4200:\ttest: 0.6983945\tbest: 0.6984809 (4180)\ttotal: 38.3s\tremaining: 52.8s\n",
      "4300:\ttest: 0.6989932\tbest: 0.6990266 (4273)\ttotal: 39.1s\tremaining: 51.9s\n",
      "4400:\ttest: 0.6995466\tbest: 0.6997902 (4382)\ttotal: 40s\tremaining: 50.9s\n",
      "4500:\ttest: 0.6998527\tbest: 0.6999065 (4482)\ttotal: 40.9s\tremaining: 50s\n",
      "4600:\ttest: 0.7005032\tbest: 0.7005059 (4598)\ttotal: 41.8s\tremaining: 49s\n",
      "4700:\ttest: 0.7009026\tbest: 0.7009653 (4695)\ttotal: 42.7s\tremaining: 48.1s\n",
      "4800:\ttest: 0.7011706\tbest: 0.7014532 (4762)\ttotal: 43.5s\tremaining: 47.1s\n",
      "4900:\ttest: 0.7016516\tbest: 0.7017977 (4891)\ttotal: 44.4s\tremaining: 46.2s\n",
      "5000:\ttest: 0.7020283\tbest: 0.7020797 (4999)\ttotal: 45.3s\tremaining: 45.2s\n",
      "5100:\ttest: 0.7024532\tbest: 0.7025971 (5072)\ttotal: 46.1s\tremaining: 44.3s\n",
      "5200:\ttest: 0.7028339\tbest: 0.7029944 (5158)\ttotal: 47s\tremaining: 43.4s\n",
      "5300:\ttest: 0.7032522\tbest: 0.7033201 (5284)\ttotal: 47.9s\tremaining: 42.5s\n",
      "5400:\ttest: 0.7036760\tbest: 0.7037364 (5375)\ttotal: 48.8s\tremaining: 41.5s\n",
      "5500:\ttest: 0.7043384\tbest: 0.7043744 (5496)\ttotal: 49.7s\tremaining: 40.7s\n",
      "5600:\ttest: 0.7046688\tbest: 0.7047622 (5592)\ttotal: 50.7s\tremaining: 39.8s\n",
      "5700:\ttest: 0.7051881\tbest: 0.7052870 (5680)\ttotal: 51.8s\tremaining: 39s\n",
      "5800:\ttest: 0.7058261\tbest: 0.7058880 (5798)\ttotal: 52.6s\tremaining: 38.1s\n",
      "5900:\ttest: 0.7060981\tbest: 0.7061119 (5894)\ttotal: 53.5s\tremaining: 37.2s\n",
      "6000:\ttest: 0.7063612\tbest: 0.7064559 (5992)\ttotal: 54.6s\tremaining: 36.4s\n",
      "6100:\ttest: 0.7067309\tbest: 0.7067331 (6096)\ttotal: 55.5s\tremaining: 35.5s\n",
      "6200:\ttest: 0.7069402\tbest: 0.7070659 (6194)\ttotal: 56.3s\tremaining: 34.5s\n",
      "6300:\ttest: 0.7075731\tbest: 0.7075973 (6293)\ttotal: 57.2s\tremaining: 33.6s\n",
      "6400:\ttest: 0.7078577\tbest: 0.7079021 (6397)\ttotal: 58.1s\tremaining: 32.7s\n",
      "6500:\ttest: 0.7079652\tbest: 0.7081097 (6471)\ttotal: 59s\tremaining: 31.8s\n",
      "6600:\ttest: 0.7083714\tbest: 0.7083714 (6600)\ttotal: 59.9s\tremaining: 30.8s\n",
      "6700:\ttest: 0.7086447\tbest: 0.7086801 (6694)\ttotal: 1m\tremaining: 29.9s\n",
      "6800:\ttest: 0.7085731\tbest: 0.7088064 (6751)\ttotal: 1m 1s\tremaining: 29s\n",
      "6900:\ttest: 0.7090065\tbest: 0.7090650 (6895)\ttotal: 1m 2s\tremaining: 28.1s\n",
      "7000:\ttest: 0.7092843\tbest: 0.7093874 (6995)\ttotal: 1m 3s\tremaining: 27.2s\n",
      "7100:\ttest: 0.7093514\tbest: 0.7096065 (7079)\ttotal: 1m 4s\tremaining: 26.2s\n",
      "7200:\ttest: 0.7094681\tbest: 0.7096065 (7079)\ttotal: 1m 5s\tremaining: 25.3s\n",
      "7300:\ttest: 0.7098846\tbest: 0.7099346 (7294)\ttotal: 1m 6s\tremaining: 24.4s\n",
      "7400:\ttest: 0.7101413\tbest: 0.7101834 (7397)\ttotal: 1m 6s\tremaining: 23.5s\n",
      "7500:\ttest: 0.7106106\tbest: 0.7106793 (7495)\ttotal: 1m 7s\tremaining: 22.6s\n",
      "7600:\ttest: 0.7110035\tbest: 0.7111205 (7595)\ttotal: 1m 8s\tremaining: 21.7s\n",
      "7700:\ttest: 0.7112679\tbest: 0.7113161 (7696)\ttotal: 1m 9s\tremaining: 20.8s\n",
      "7800:\ttest: 0.7118324\tbest: 0.7119481 (7794)\ttotal: 1m 10s\tremaining: 19.9s\n",
      "7900:\ttest: 0.7123247\tbest: 0.7123436 (7897)\ttotal: 1m 11s\tremaining: 19s\n",
      "8000:\ttest: 0.7127706\tbest: 0.7127808 (7999)\ttotal: 1m 12s\tremaining: 18.1s\n",
      "8100:\ttest: 0.7127256\tbest: 0.7128621 (8006)\ttotal: 1m 13s\tremaining: 17.2s\n",
      "8200:\ttest: 0.7130960\tbest: 0.7131125 (8198)\ttotal: 1m 14s\tremaining: 16.3s\n",
      "8300:\ttest: 0.7131137\tbest: 0.7132486 (8274)\ttotal: 1m 15s\tremaining: 15.4s\n",
      "8400:\ttest: 0.7131496\tbest: 0.7132486 (8274)\ttotal: 1m 16s\tremaining: 14.6s\n",
      "8500:\ttest: 0.7134413\tbest: 0.7135680 (8496)\ttotal: 1m 17s\tremaining: 13.7s\n",
      "8600:\ttest: 0.7137598\tbest: 0.7138109 (8596)\ttotal: 1m 18s\tremaining: 12.8s\n",
      "8700:\ttest: 0.7139848\tbest: 0.7141654 (8681)\ttotal: 1m 20s\tremaining: 11.9s\n",
      "8800:\ttest: 0.7141890\tbest: 0.7143170 (8776)\ttotal: 1m 21s\tremaining: 11.1s\n",
      "8900:\ttest: 0.7144646\tbest: 0.7146941 (8893)\ttotal: 1m 22s\tremaining: 10.2s\n",
      "9000:\ttest: 0.7146387\tbest: 0.7147420 (8952)\ttotal: 1m 23s\tremaining: 9.27s\n",
      "9100:\ttest: 0.7148295\tbest: 0.7149629 (9047)\ttotal: 1m 24s\tremaining: 8.35s\n",
      "9200:\ttest: 0.7148864\tbest: 0.7150536 (9167)\ttotal: 1m 25s\tremaining: 7.44s\n",
      "9300:\ttest: 0.7151787\tbest: 0.7153193 (9280)\ttotal: 1m 26s\tremaining: 6.52s\n",
      "9400:\ttest: 0.7153580\tbest: 0.7154220 (9393)\ttotal: 1m 27s\tremaining: 5.58s\n",
      "9500:\ttest: 0.7154986\tbest: 0.7156898 (9448)\ttotal: 1m 28s\tremaining: 4.66s\n",
      "9600:\ttest: 0.7157882\tbest: 0.7158715 (9598)\ttotal: 1m 29s\tremaining: 3.72s\n",
      "9700:\ttest: 0.7160471\tbest: 0.7162071 (9693)\ttotal: 1m 30s\tremaining: 2.79s\n",
      "9800:\ttest: 0.7162078\tbest: 0.7162360 (9778)\ttotal: 1m 31s\tremaining: 1.86s\n",
      "9900:\ttest: 0.7166806\tbest: 0.7167721 (9894)\ttotal: 1m 32s\tremaining: 929ms\n",
      "9999:\ttest: 0.7168984\tbest: 0.7168984 (9999)\ttotal: 1m 34s\tremaining: 0us\n",
      "bestTest = 0.7168983646\n",
      "bestIteration = 9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7ff2c8259198>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(**catboost_params)\n",
    "model.fit(train_pool, eval_set=valid_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: why are so many people paying so much and putting themselves at risk for a placebo effect via the upshot http ift tt 2spavjc\n",
      "Predict label:  [0]\n",
      "True label:  0\n"
     ]
    }
   ],
   "source": [
    "# делаем пробное предсказание\n",
    "tweet_index = random.randint(1,8000)\n",
    "\n",
    "print('Text: ' + df_tweets['text'][tweet_index])\n",
    "print('Predict label: ', model.predict(features[tweet_index:tweet_index+1][:])[0])\n",
    "print('True label: ', df_tweets['target'][tweet_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60375"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# оцениваем accuracy на тестовой выборке\n",
    "\n",
    "model.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:15<00:00, 265.43it/s]\n"
     ]
    }
   ],
   "source": [
    "d = []\n",
    "for idx, tt in enumerate(tqdm(df_tweets['text'].head(4000))):\n",
    "    try:\n",
    "        d.append(\n",
    "            {\n",
    "                'text': tt,\n",
    "                'predict': model.predict(features[idx:idx+1][:])[0][0],\n",
    "                'gtrue': df_tweets['target'][idx]\n",
    "            }\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    #print(max(res,key=itemgetter(1))[0])    \n",
    "df_train = pd.DataFrame(d)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3650\n",
       "1     261\n",
       "2      89\n",
       "Name: predict, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.predict.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2410\n",
       "1    1032\n",
       "2     558\n",
       "Name: gtrue, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.gtrue.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def confusion_matrix(df: pd.DataFrame, col1: str, col2: str):\n",
    "    \"\"\"\n",
    "    Given a dataframe with at least\n",
    "    two categorical columns, create a \n",
    "    confusion matrix of the count of the columns\n",
    "    cross-counts\n",
    "    \n",
    "    use like:\n",
    "    \n",
    "    >>> confusion_matrix(test_df, 'actual_label', 'predicted_label')\n",
    "    \"\"\"\n",
    "    return (\n",
    "            df\n",
    "            .groupby([col1, col2])\n",
    "            .size()\n",
    "            .unstack(fill_value=0)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gtrue</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2393</td>\n",
       "      <td>790</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>237</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gtrue       0    1    2\n",
       "predict                \n",
       "0        2393  790  467\n",
       "1          13  237   11\n",
       "2           4    5   80"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_train,'predict','gtrue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renat/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучаем классификатор на основе логистической регрессии\n",
    "\n",
    "lr_clf = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: migration racial or ethnic self identity and marriage were among the many topics explored at the population association of america s annual meeting last month via pew research center https ift tt 2imome2\n",
      "Predict label:  0\n",
      "True label:  0\n"
     ]
    }
   ],
   "source": [
    "# делаем пробное предсказание\n",
    "tweet_index = random.randint(1,8000)\n",
    "\n",
    "print('Text: ' + df_tweets['text'][tweet_index])\n",
    "print('Predict label: ', lr_clf.predict(features[tweet_index:tweet_index+1][:])[0])\n",
    "print('True label: ', df_tweets['target'][tweet_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5125"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# оцениваем accuracy на тестовой выборке\n",
    "\n",
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:00<00:00, 13291.46it/s]\n"
     ]
    }
   ],
   "source": [
    "d = []\n",
    "for idx, tt in enumerate(tqdm(df_tweets['text'].head(4000))):\n",
    "    try:\n",
    "        d.append(\n",
    "            {\n",
    "                'text': tt,\n",
    "                'predict': lr_clf.predict(features[idx:idx+1][:])[0],\n",
    "                'gtrue': df_tweets['target'][idx]\n",
    "            }\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    #print(max(res,key=itemgetter(1))[0])    \n",
    "df_train = pd.DataFrame(d)    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1867\n",
       "1    1210\n",
       "2     923\n",
       "Name: predict, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.predict.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2410\n",
       "1    1032\n",
       "2     558\n",
       "Name: gtrue, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.gtrue.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def confusion_matrix(df: pd.DataFrame, col1: str, col2: str):\n",
    "    \"\"\"\n",
    "    Given a dataframe with at least\n",
    "    two categorical columns, create a \n",
    "    confusion matrix of the count of the columns\n",
    "    cross-counts\n",
    "    \n",
    "    use like:\n",
    "    \n",
    "    >>> confusion_matrix(test_df, 'actual_label', 'predicted_label')\n",
    "    \"\"\"\n",
    "    return (\n",
    "            df\n",
    "            .groupby([col1, col2])\n",
    "            .size()\n",
    "            .unstack(fill_value=0)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gtrue</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1479</td>\n",
       "      <td>275</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>532</td>\n",
       "      <td>609</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>399</td>\n",
       "      <td>148</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gtrue       0    1    2\n",
       "predict                \n",
       "0        1479  275  113\n",
       "1         532  609   69\n",
       "2         399  148  376"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_train,'predict','gtrue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
